{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import fsspec\n",
    "import geopandas as gpd\n",
    "\n",
    "from utils import get_logger\n",
    "from utils.dask import create_cluster\n",
    "from utils.hls.catalog import HLSCatalog\n",
    "from utils.hls.catalog import HLSBand\n",
    "from utils.hls.compute import calculate_job_median\n",
    "from utils.hls.compute import jobs_from_catalog, process_jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "j = gpd.read_file('./cb_2019_us_state_5m.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['AZURE_STORAGE_ACCOUNT'] = 'lumonitor'\n",
    "#os.environ['AZURE_STORAGE_ACCESS_KEY'] = 'PQuse/8Q7kLuAFiPYlVEaHtgrAW1H3z0W3dGJLdhQ4S5DZRKvR2sWeNzHOsA86KGKdGUs6IWP6y/tVRH8XGKlg=='\n",
    "os.environ['AZURE_STORAGE_ACCESS_KEY'] = 'lpvjCOKmzRrI0t+6BOVwbKHbsMwNPbwZgSB4aticQ5lpZBFX29jOZq1+y5uGFzNJSLQm1XOUSdEMD1j4ZzOTtA=='\n",
    "# This stopped working on pangeo upgrade on 25Mar2021\n",
    "# tiger_states  = gpd.read_file('zip+http://www2.census.gov/geo/tiger/GENZ2019/shp/cb_2019_us_state_5m.zip').to_crs('EPSG:4326')\n",
    "\n",
    "tiger_states = gpd.read_file('./cb_2019_us_state_5m.zip').to_crs('EPSG:4326')\n",
    "california = tiger_states[tiger_states['NAME']=='California']\n",
    "\n",
    "bands = [\n",
    "    HLSBand.COASTAL_AEROSOL,\n",
    "    HLSBand.BLUE,\n",
    "    HLSBand.GREEN,\n",
    "    HLSBand.RED,\n",
    "    HLSBand.NIR_NARROW,\n",
    "    HLSBand.SWIR1,\n",
    "    HLSBand.SWIR2,\n",
    "    HLSBand.QA  # needed for qa\n",
    "]\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading tile extents...\n",
      "Read tile extents for 56686 tiles\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (index: 2171)\n",
      "Coordinates:\n",
      "  * index    (index) int64 0 0 0 0 0 0 0 0 0 0 ... 73 73 73 73 73 73 73 73 73 73\n",
      "Data variables:\n",
      "    tile     (index) object '10SEF' '10SEF' '10SEF' ... '10SDH' '10SDH' '10SDH'\n",
      "    year     (index) object 2013 2013 2013 2013 2013 ... 2013 2013 2013 2013\n",
      "    scene    (index) object 'L30/HLS.L30.T10SEF.2013106.v1.4' ... 'L30/HLS.L3...\n",
      "    sensor   (index) object 'L' 'L' 'L' 'L' 'L' 'L' ... 'L' 'L' 'L' 'L' 'L' 'L'\n",
      "    dt       (index) datetime64[ns] 2013-04-16 2013-04-25 ... 2013-12-26\n",
      "Attributes:\n",
      "    bands:    [<HLSBand.COASTAL_AEROSOL: 1>, <HLSBand.BLUE: 2>, <HLSBand.GREE...\n"
     ]
    }
   ],
   "source": [
    "catalog = HLSCatalog.from_geom(geom=california, years=[2013], bands=bands)\n",
    "\n",
    "# read the entire data once (each tile is 3660x3660)...\n",
    "chunks = {'band': 1, 'x': 3660, 'y': 3660}\n",
    "\n",
    "logger = get_logger('hls-conus-2016')\n",
    "\n",
    "catalog.xr_ds = catalog.xr_ds.where(catalog.xr_ds['year']== 2013, drop=True)\n",
    "# Had to do this as 2 steps b/c I was getting an error about duplicate indices\n",
    "catalog.xr_ds = catalog.xr_ds.where(catalog.xr_ds['sensor']== 'L', drop=True)\n",
    "\n",
    "print(catalog.xr_ds)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-03-26 00:26:16,687 [INFO] hls-conus-2016 - Starting cluster\n",
      "2021-03-26 00:26:16,687 [INFO] hls-conus-2016 - Starting cluster\n",
      "2021-03-26 00:26:16,687 [INFO] hls-conus-2016 - Starting cluster\n",
      "2021-03-26 00:26:16,687 [INFO] hls-conus-2016 - Starting cluster\n",
      "2021-03-26 00:26:16,687 [INFO] hls-conus-2016 - Starting cluster\n",
      "2021-03-26 00:26:16,687 [INFO] hls-conus-2016 - Starting cluster\n",
      "2021-03-26 00:26:26,572 [INFO] hls-conus-2016 - Cluster dashboard visible at /services/dask-gateway/clusters/default.4f17a959d44c4868a4c43b8543e8ecec/status\n",
      "2021-03-26 00:26:26,572 [INFO] hls-conus-2016 - Cluster dashboard visible at /services/dask-gateway/clusters/default.4f17a959d44c4868a4c43b8543e8ecec/status\n",
      "2021-03-26 00:26:26,572 [INFO] hls-conus-2016 - Cluster dashboard visible at /services/dask-gateway/clusters/default.4f17a959d44c4868a4c43b8543e8ecec/status\n",
      "2021-03-26 00:26:26,572 [INFO] hls-conus-2016 - Cluster dashboard visible at /services/dask-gateway/clusters/default.4f17a959d44c4868a4c43b8543e8ecec/status\n",
      "2021-03-26 00:26:26,572 [INFO] hls-conus-2016 - Cluster dashboard visible at /services/dask-gateway/clusters/default.4f17a959d44c4868a4c43b8543e8ecec/status\n",
      "2021-03-26 00:26:26,572 [INFO] hls-conus-2016 - Cluster dashboard visible at /services/dask-gateway/clusters/default.4f17a959d44c4868a4c43b8543e8ecec/status\n",
      "2021-03-26 00:26:26,599 [INFO] hls-conus-2016 - Uploading code to cluster\n",
      "2021-03-26 00:26:26,599 [INFO] hls-conus-2016 - Uploading code to cluster\n",
      "2021-03-26 00:26:26,599 [INFO] hls-conus-2016 - Uploading code to cluster\n",
      "2021-03-26 00:26:26,599 [INFO] hls-conus-2016 - Uploading code to cluster\n",
      "2021-03-26 00:26:26,599 [INFO] hls-conus-2016 - Uploading code to cluster\n",
      "2021-03-26 00:26:26,599 [INFO] hls-conus-2016 - Uploading code to cluster\n",
      "2021-03-26 00:26:26,605 [INFO] hls-conus-2016 - Submitting job 10SDH\n",
      "2021-03-26 00:26:26,605 [INFO] hls-conus-2016 - Submitting job 10SDH\n",
      "2021-03-26 00:26:26,605 [INFO] hls-conus-2016 - Submitting job 10SDH\n",
      "2021-03-26 00:26:26,605 [INFO] hls-conus-2016 - Submitting job 10SDH\n",
      "2021-03-26 00:26:26,605 [INFO] hls-conus-2016 - Submitting job 10SDH\n",
      "2021-03-26 00:26:26,605 [INFO] hls-conus-2016 - Submitting job 10SDH\n",
      "2021-03-26 00:26:26,609 [INFO] hls-conus-2016 - Submitting job 10SDJ\n",
      "2021-03-26 00:26:26,609 [INFO] hls-conus-2016 - Submitting job 10SDJ\n",
      "2021-03-26 00:26:26,609 [INFO] hls-conus-2016 - Submitting job 10SDJ\n",
      "2021-03-26 00:26:26,609 [INFO] hls-conus-2016 - Submitting job 10SDJ\n",
      "2021-03-26 00:26:26,609 [INFO] hls-conus-2016 - Submitting job 10SDJ\n",
      "2021-03-26 00:26:26,609 [INFO] hls-conus-2016 - Submitting job 10SDJ\n",
      "2021-03-26 00:26:26,613 [INFO] hls-conus-2016 - Submitting job 10SEF\n",
      "2021-03-26 00:26:26,613 [INFO] hls-conus-2016 - Submitting job 10SEF\n",
      "2021-03-26 00:26:26,613 [INFO] hls-conus-2016 - Submitting job 10SEF\n",
      "2021-03-26 00:26:26,613 [INFO] hls-conus-2016 - Submitting job 10SEF\n",
      "2021-03-26 00:26:26,613 [INFO] hls-conus-2016 - Submitting job 10SEF\n",
      "2021-03-26 00:26:26,613 [INFO] hls-conus-2016 - Submitting job 10SEF\n",
      "2021-03-26 00:26:26,618 [INFO] hls-conus-2016 - Submitting job 10SEG\n",
      "2021-03-26 00:26:26,618 [INFO] hls-conus-2016 - Submitting job 10SEG\n",
      "2021-03-26 00:26:26,618 [INFO] hls-conus-2016 - Submitting job 10SEG\n",
      "2021-03-26 00:26:26,618 [INFO] hls-conus-2016 - Submitting job 10SEG\n",
      "2021-03-26 00:26:26,618 [INFO] hls-conus-2016 - Submitting job 10SEG\n",
      "2021-03-26 00:26:26,618 [INFO] hls-conus-2016 - Submitting job 10SEG\n"
     ]
    }
   ],
   "source": [
    "jobs = jobs_from_catalog(catalog.xr_ds, 'tile')\n",
    "\n",
    "cluster_args = dict(\n",
    "    workers=64,\n",
    "    worker_threads=1,\n",
    "    worker_memory=8,\n",
    "    scheduler_threads=4,\n",
    "    scheduler_memory=8,\n",
    "    environment_options = dict(\n",
    "        AZURE_STORAGE_ACCOUNT='lumonitor',\n",
    "        AZURE_STORAGE_ACCESS_KEY='lpvjCOKmzRrI0t+6BOVwbKHbsMwNPbwZgSB4aticQ5lpZBFX29jOZq1+y5uGFzNJSLQm1XOUSdEMD1j4ZzOTtA==',\n",
    "        CPL_VSIL_USE_TEMP_FILE_FOR_RANDOM_WRITE='YES'\n",
    "    )\n",
    ")\n",
    "\n",
    "process_jobs(\n",
    "    jobs=jobs,\n",
    "    job_fn=calculate_job_median,\n",
    "    concurrency=4,\n",
    "    checkpoint_path='./checkpoint',\n",
    "    logger=logger,\n",
    "    cluster_args=cluster_args,\n",
    "    code_path='./utils',\n",
    "    job_groupby='time.year',\n",
    "    bands=bands,\n",
    "    chunks=chunks,\n",
    "    account_name=os.environ['AZURE_STORAGE_ACCOUNT'],\n",
    "    account_key=os.environ['AZURE_STORAGE_ACCESS_KEY'],\n",
    "    storage_container='lumonitor',\n",
    "    subfolder='2013'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
