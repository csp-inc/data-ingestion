{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# pip/conda installed\n",
    "import fsspec\n",
    "\n",
    "from utils import get_logger\n",
    "from utils.hls.catalog import HLSCatalog\n",
    "from utils.hls.compute import process_jobs\n",
    "from utils.hls.compute import jobs_from_catalog\n",
    "from utils.hls.compute import calculate_job_median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = get_logger('hls-conus')\n",
    "cluster_args = dict(\n",
    "    workers=64,\n",
    "    worker_threads=1,\n",
    "    worker_memory=8,\n",
    "    scheduler_threads=4,\n",
    "    scheduler_memory=8\n",
    ")\n",
    "code_path = './utils'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill with your account key\n",
    "os.environ['AZURE_ACCOUNT_KEY'] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "catalog_url = fsspec.get_mapper(\n",
    "    f\"az://fia/catalogs/hls_conus_2015-2019.zarr\",\n",
    "    account_name=\"usfs\",\n",
    "    account_key=os.environ['AZURE_ACCOUNT_KEY']\n",
    ")\n",
    "catalog = HLSCatalog.from_zarr(catalog_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kwargs for calculate_job_median\n",
    "account_name = \"usfs\"\n",
    "storage_container = \"fia/hls\"\n",
    "account_key = os.environ[\"AZURE_ACCOUNT_KEY\"]\n",
    "job_groupby = \"time.month\"\n",
    "bands = catalog.xr_ds.attrs['bands']\n",
    "chunks = {'band': 1, 'x': 3660, 'y': 3660} # read an entire tile once (each tile is 3660x3660)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter to scenes from 2015 and later, then group by year\n",
    "yr_catalogs = catalog.xr_ds.where(catalog.xr_ds['year'] >= 2015, drop=True).groupby('year')\n",
    "\n",
    "# catalog -> job args\n",
    "catalog_groupby = \"tile\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-02-05 22:16:05,315 [INFO] hls-conus - Starting process for 2015.0\n",
      "xarray.Dataset {\n",
      "dimensions:\n",
      "\tindex = 52082 ;\n",
      "\n",
      "variables:\n",
      "\tdatetime64[ns] dt(index) ;\n",
      "\tobject scene(index) ;\n",
      "\tobject sensor(index) ;\n",
      "\tobject tile(index) ;\n",
      "\tfloat64 year(index) ;\n",
      "\tint64 index(index) ;\n",
      "\n",
      "// global attributes:\n",
      "\t:bands = [<HLSBand.COASTAL_AEROSOL: 1>, <HLSBand.BLUE: 2>, <HLSBand.GREEN: 3>, <HLSBand.RED: 4>, <HLSBand.NIR_NARROW: 5>, <HLSBand.SWIR1: 6>, <HLSBand.SWIR2: 7>, <HLSBand.CIRRUS: 8>, <HLSBand.QA: 11>] ;\n",
      "}2021-02-05 22:16:06,045 [INFO] hls-conus - Starting cluster\n",
      "2021-02-05 22:16:16,855 [INFO] hls-conus - Cluster dashboard visible at /services/dask-gateway/clusters/default.cf4333e3a17a412e85154e5b397ed371/status\n",
      "2021-02-05 22:16:16,878 [INFO] hls-conus - Uploading code to cluster\n",
      "2021-02-05 22:16:16,881 [INFO] hls-conus - Submitting job 17SMD\n",
      "2021-02-05 22:16:33,546 [ERROR] hls-conus - Exception from dask cluster\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jovyan/data-ingestion/utils/hls/compute.py\", line 251, in run_job_subset\n",
      "    result = future.result()\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.8/site-packages/distributed/client.py\", line 224, in result\n",
      "    raise exc.with_traceback(tb)\n",
      "  File \"/home/jovyan/dask-worker-space/dask-worker-space/worker-7t9l0ayt/source.zip/utils/hls/compute.py\", line 177, in calculate_job_median\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.8/site-packages/dask/base.py\", line 561, in compute\n",
      "    results = schedule(dsk, keys, **kwargs)\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.8/site-packages/distributed/client.py\", line 2684, in get\n",
      "    results = self.gather(packed, asynchronous=asynchronous, direct=direct)\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.8/site-packages/distributed/client.py\", line 1993, in gather\n",
      "    return self.sync(\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.8/site-packages/distributed/client.py\", line 839, in sync\n",
      "    return sync(\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.8/site-packages/distributed/utils.py\", line 340, in sync\n",
      "    raise exc.with_traceback(tb)\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.8/site-packages/distributed/utils.py\", line 324, in f\n",
      "    result[0] = yield future\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.8/site-packages/tornado/gen.py\", line 762, in run\n",
      "    value = future.result()\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.8/site-packages/distributed/client.py\", line 1858, in _gather\n",
      "    raise exception.with_traceback(traceback)\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.8/site-packages/dask/utils.py\", line 31, in apply\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/jovyan/dask-worker-space/dask-worker-space/worker-7t9l0ayt/source.zip/utils/hls/compute.py\", line 85, in get_scene_dataset\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.8/site-packages/xarray/core/merge.py\", line 857, in merge\n",
      "    merge_result = merge_core(\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.8/site-packages/xarray/core/merge.py\", line 591, in merge_core\n",
      "    aligned = deep_align(\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.8/site-packages/xarray/core/alignment.py\", line 421, in deep_align\n",
      "    aligned = align(\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.8/site-packages/xarray/core/alignment.py\", line 353, in align\n",
      "    new_obj = obj.reindex(\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.8/site-packages/xarray/core/dataset.py\", line 2623, in reindex\n",
      "    return self._reindex(\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.8/site-packages/xarray/core/dataset.py\", line 2652, in _reindex\n",
      "    variables, indexes = alignment.reindex_variables(\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.8/site-packages/xarray/core/alignment.py\", line 565, in reindex_variables\n",
      "    raise ValueError(\n",
      "ValueError: cannot reindex or align along dimension 'y' because the index has duplicate values\n",
      "2021-02-05 22:16:33,551 [INFO] hls-conus - ()\n",
      "2021-02-05 22:16:33,591 [INFO] hls-conus - Metrics: {\"job_errors\": 1, \"job_skips\": 975, \"job_completes\": 0, \"time\": 27.56821883795783}\n",
      "2021-02-05 22:16:33,666 [INFO] hls-conus - Starting process for 2016.0\n",
      "xarray.Dataset {\n",
      "dimensions:\n",
      "\tindex = 84039 ;\n",
      "\n",
      "variables:\n",
      "\tdatetime64[ns] dt(index) ;\n",
      "\tobject scene(index) ;\n",
      "\tobject sensor(index) ;\n",
      "\tobject tile(index) ;\n",
      "\tfloat64 year(index) ;\n",
      "\tint64 index(index) ;\n",
      "\n",
      "// global attributes:\n",
      "\t:bands = [<HLSBand.COASTAL_AEROSOL: 1>, <HLSBand.BLUE: 2>, <HLSBand.GREEN: 3>, <HLSBand.RED: 4>, <HLSBand.NIR_NARROW: 5>, <HLSBand.SWIR1: 6>, <HLSBand.SWIR2: 7>, <HLSBand.CIRRUS: 8>, <HLSBand.QA: 11>] ;\n",
      "}2021-02-05 22:16:34,536 [INFO] hls-conus - Metrics: {\"job_errors\": 0, \"job_skips\": 976, \"job_completes\": 0, \"time\": 0.02484672493301332}\n",
      "2021-02-05 22:16:34,630 [INFO] hls-conus - Starting process for 2017.0\n",
      "xarray.Dataset {\n",
      "dimensions:\n",
      "\tindex = 110582 ;\n",
      "\n",
      "variables:\n",
      "\tdatetime64[ns] dt(index) ;\n",
      "\tobject scene(index) ;\n",
      "\tobject sensor(index) ;\n",
      "\tobject tile(index) ;\n",
      "\tfloat64 year(index) ;\n",
      "\tint64 index(index) ;\n",
      "\n",
      "// global attributes:\n",
      "\t:bands = [<HLSBand.COASTAL_AEROSOL: 1>, <HLSBand.BLUE: 2>, <HLSBand.GREEN: 3>, <HLSBand.RED: 4>, <HLSBand.NIR_NARROW: 5>, <HLSBand.SWIR1: 6>, <HLSBand.SWIR2: 7>, <HLSBand.CIRRUS: 8>, <HLSBand.QA: 11>] ;\n",
      "}2021-02-05 22:16:35,324 [INFO] hls-conus - Metrics: {\"job_errors\": 0, \"job_skips\": 976, \"job_completes\": 0, \"time\": 0.029342967085540295}\n",
      "2021-02-05 22:16:35,465 [INFO] hls-conus - Starting process for 2018.0\n",
      "xarray.Dataset {\n",
      "dimensions:\n",
      "\tindex = 170472 ;\n",
      "\n",
      "variables:\n",
      "\tdatetime64[ns] dt(index) ;\n",
      "\tobject scene(index) ;\n",
      "\tobject sensor(index) ;\n",
      "\tobject tile(index) ;\n",
      "\tfloat64 year(index) ;\n",
      "\tint64 index(index) ;\n",
      "\n",
      "// global attributes:\n",
      "\t:bands = [<HLSBand.COASTAL_AEROSOL: 1>, <HLSBand.BLUE: 2>, <HLSBand.GREEN: 3>, <HLSBand.RED: 4>, <HLSBand.NIR_NARROW: 5>, <HLSBand.SWIR1: 6>, <HLSBand.SWIR2: 7>, <HLSBand.CIRRUS: 8>, <HLSBand.QA: 11>] ;\n",
      "}2021-02-05 22:16:36,173 [INFO] hls-conus - Starting cluster\n",
      "2021-02-05 22:16:44,771 [INFO] hls-conus - Cluster dashboard visible at /services/dask-gateway/clusters/default.73847ca5780e47fc921cd7024d40acef/status\n",
      "2021-02-05 22:16:44,795 [INFO] hls-conus - Uploading code to cluster\n",
      "2021-02-05 22:16:44,798 [INFO] hls-conus - Submitting job 13SBS\n",
      "2021-02-05 22:16:44,800 [INFO] hls-conus - Submitting job 14TKK\n",
      "2021-02-05 22:20:09,779 [INFO] hls-conus - Completed job 13SBS\n",
      "2021-02-05 22:20:09,780 [INFO] hls-conus - Submitting job 14TLQ\n",
      "2021-02-05 22:20:15,517 [INFO] hls-conus - Completed job 14TKK\n",
      "2021-02-05 22:21:34,998 [INFO] hls-conus - Completed job 14TLQ\n",
      "2021-02-05 22:21:35,001 [INFO] hls-conus - ()\n",
      "2021-02-05 22:21:35,342 [INFO] hls-conus - Metrics: {\"job_errors\": 0, \"job_skips\": 973, \"job_completes\": 3, \"time\": 299.205591626931}\n",
      "2021-02-05 22:21:35,497 [INFO] hls-conus - Starting process for 2019.0\n",
      "xarray.Dataset {\n",
      "dimensions:\n",
      "\tindex = 181914 ;\n",
      "\n",
      "variables:\n",
      "\tdatetime64[ns] dt(index) ;\n",
      "\tobject scene(index) ;\n",
      "\tobject sensor(index) ;\n",
      "\tobject tile(index) ;\n",
      "\tfloat64 year(index) ;\n",
      "\tint64 index(index) ;\n",
      "\n",
      "// global attributes:\n",
      "\t:bands = [<HLSBand.COASTAL_AEROSOL: 1>, <HLSBand.BLUE: 2>, <HLSBand.GREEN: 3>, <HLSBand.RED: 4>, <HLSBand.NIR_NARROW: 5>, <HLSBand.SWIR1: 6>, <HLSBand.SWIR2: 7>, <HLSBand.CIRRUS: 8>, <HLSBand.QA: 11>] ;\n",
      "}2021-02-05 22:21:36,332 [INFO] hls-conus - Starting cluster\n",
      "2021-02-05 22:21:44,589 [INFO] hls-conus - Cluster dashboard visible at /services/dask-gateway/clusters/default.59d11e5663044514a77c71477e8150aa/status\n",
      "2021-02-05 22:21:44,614 [INFO] hls-conus - Uploading code to cluster\n",
      "2021-02-05 22:21:44,616 [INFO] hls-conus - Submitting job 13TGJ\n",
      "2021-02-05 22:21:44,618 [INFO] hls-conus - Submitting job 15RTN\n",
      "2021-02-05 22:26:21,013 [INFO] hls-conus - Completed job 15RTN\n",
      "2021-02-05 22:26:21,014 [INFO] hls-conus - Submitting job 15SVV\n",
      "2021-02-05 22:26:25,394 [INFO] hls-conus - Completed job 13TGJ\n",
      "2021-02-05 22:26:25,395 [INFO] hls-conus - Submitting job 15SWU\n",
      "2021-02-05 22:26:56,747 [ERROR] hls-conus - Exception from dask cluster\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jovyan/data-ingestion/utils/hls/compute.py\", line 251, in run_job_subset\n",
      "    result = future.result()\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.8/site-packages/distributed/client.py\", line 224, in result\n",
      "    raise exc.with_traceback(tb)\n",
      "  File \"/home/jovyan/dask-worker-space/dask-worker-space/worker-fq86y7c1/source.zip/utils/hls/compute.py\", line 182, in calculate_job_median\n",
      "  File \"/home/jovyan/dask-worker-space/dask-worker-space/worker-fq86y7c1/source.zip/utils/hls/compute.py\", line 106, in compute_tile_median\n",
      "  File \"/home/jovyan/dask-worker-space/dask-worker-space/worker-fq86y7c1/source.zip/utils/hls/compute.py\", line 36, in get_mask\n",
      "  File \"/home/jovyan/dask-worker-space/dask-worker-space/worker-fq86y7c1/source.zip/utils/hls/compute.py\", line 34, in is_bad_quality\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.8/site-packages/xarray/core/dataarray.py\", line 2914, in func\n",
      "    f(self.variable, other_variable)\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.8/site-packages/xarray/core/variable.py\", line 2195, in func\n",
      "    f(self_data, other_data)\n",
      "TypeError: unsupported operand type(s) for &: 'Array' and 'int'\n",
      "2021-02-05 22:26:56,749 [INFO] hls-conus - Submitting job 17TNF\n",
      "2021-02-05 22:27:11,868 [ERROR] hls-conus - Exception from dask cluster\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jovyan/data-ingestion/utils/hls/compute.py\", line 251, in run_job_subset\n",
      "    result = future.result()\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.8/site-packages/distributed/client.py\", line 224, in result\n",
      "    raise exc.with_traceback(tb)\n",
      "  File \"/home/jovyan/dask-worker-space/dask-worker-space/worker-hszkxayd/source.zip/utils/hls/compute.py\", line 182, in calculate_job_median\n",
      "  File \"/home/jovyan/dask-worker-space/dask-worker-space/worker-hszkxayd/source.zip/utils/hls/compute.py\", line 106, in compute_tile_median\n",
      "  File \"/home/jovyan/dask-worker-space/dask-worker-space/worker-hszkxayd/source.zip/utils/hls/compute.py\", line 36, in get_mask\n",
      "  File \"/home/jovyan/dask-worker-space/dask-worker-space/worker-hszkxayd/source.zip/utils/hls/compute.py\", line 34, in is_bad_quality\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.8/site-packages/xarray/core/dataarray.py\", line 2914, in func\n",
      "    f(self.variable, other_variable)\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.8/site-packages/xarray/core/variable.py\", line 2195, in func\n",
      "    f(self_data, other_data)\n",
      "TypeError: unsupported operand type(s) for &: 'Array' and 'int'\n",
      "2021-02-05 22:27:11,870 [INFO] hls-conus - Submitting job 19TEL\n",
      "2021-02-05 22:27:47,998 [ERROR] hls-conus - Exception from dask cluster\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jovyan/data-ingestion/utils/hls/compute.py\", line 251, in run_job_subset\n",
      "    result = future.result()\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.8/site-packages/distributed/client.py\", line 224, in result\n",
      "    raise exc.with_traceback(tb)\n",
      "  File \"/home/jovyan/dask-worker-space/dask-worker-space/worker-14nyz8kt/source.zip/utils/hls/compute.py\", line 182, in calculate_job_median\n",
      "  File \"/home/jovyan/dask-worker-space/dask-worker-space/worker-14nyz8kt/source.zip/utils/hls/compute.py\", line 106, in compute_tile_median\n",
      "  File \"/home/jovyan/dask-worker-space/dask-worker-space/worker-14nyz8kt/source.zip/utils/hls/compute.py\", line 36, in get_mask\n",
      "  File \"/home/jovyan/dask-worker-space/dask-worker-space/worker-14nyz8kt/source.zip/utils/hls/compute.py\", line 34, in is_bad_quality\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.8/site-packages/xarray/core/dataarray.py\", line 2914, in func\n",
      "    f(self.variable, other_variable)\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.8/site-packages/xarray/core/variable.py\", line 2195, in func\n",
      "    f(self_data, other_data)\n",
      "TypeError: unsupported operand type(s) for &: 'Array' and 'int'\n",
      "2021-02-05 22:28:04,782 [ERROR] hls-conus - Exception from dask cluster\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jovyan/data-ingestion/utils/hls/compute.py\", line 251, in run_job_subset\n",
      "    result = future.result()\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.8/site-packages/distributed/client.py\", line 224, in result\n",
      "    raise exc.with_traceback(tb)\n",
      "  File \"/home/jovyan/dask-worker-space/dask-worker-space/worker-clco5l5t/source.zip/utils/hls/compute.py\", line 182, in calculate_job_median\n",
      "  File \"/home/jovyan/dask-worker-space/dask-worker-space/worker-clco5l5t/source.zip/utils/hls/compute.py\", line 106, in compute_tile_median\n",
      "  File \"/home/jovyan/dask-worker-space/dask-worker-space/worker-clco5l5t/source.zip/utils/hls/compute.py\", line 36, in get_mask\n",
      "  File \"/home/jovyan/dask-worker-space/dask-worker-space/worker-clco5l5t/source.zip/utils/hls/compute.py\", line 34, in is_bad_quality\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.8/site-packages/xarray/core/dataarray.py\", line 2914, in func\n",
      "    f(self.variable, other_variable)\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.8/site-packages/xarray/core/variable.py\", line 2195, in func\n",
      "    f(self_data, other_data)\n",
      "TypeError: unsupported operand type(s) for &: 'Array' and 'int'\n",
      "2021-02-05 22:28:04,784 [INFO] hls-conus - ()\n",
      "2021-02-05 22:28:04,867 [INFO] hls-conus - Metrics: {\"job_errors\": 4, \"job_skips\": 970, \"job_completes\": 2, \"time\": 388.5792020200752}\n"
     ]
    }
   ],
   "source": [
    "for yr, ca in yr_catalogs:\n",
    "    logger.info(f\"Starting process for {yr}\")\n",
    "    ca.info()\n",
    "    storage_prefix = f\"{storage_container}/{yr}\"\n",
    "    checkpoint_path = f\"checkpoints/{yr}.txt\"\n",
    "    jobs = jobs_from_catalog(ca, catalog_groupby)\n",
    "    process_jobs(\n",
    "        jobs=jobs,\n",
    "        job_fn=calculate_job_median,\n",
    "        checkpoint_path=checkpoint_path,\n",
    "        logger=logger,\n",
    "        cluster_args=cluster_args,\n",
    "        code_path=code_path,\n",
    "        concurrency=2,  # run 2 jobs at once\n",
    "        cluster_restart_freq=16,  # restart after 16 jobs\n",
    "        # kwargs for calculate_job_median\n",
    "        job_groupby=job_groupby,\n",
    "        bands=bands,\n",
    "        chunks=chunks,\n",
    "        account_name=account_name,\n",
    "        storage_container=storage_prefix,\n",
    "        account_key=account_key,\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:notebook] *",
   "language": "python",
   "name": "conda-env-notebook-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
